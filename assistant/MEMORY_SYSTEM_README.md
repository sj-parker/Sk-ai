# Система долгосрочной памяти

## Обзор

Новая система долгосрочной памяти автоматически подмешивает факты о пользователе в контекст LLM при каждом обращении из Twitch, YouTube, Telegram и других источников.

## Как это работает

### 1. Сохранение фактов
Пользователь пишет сообщения с ключевыми словами:
- `запомни не люблю лето`
- `запомни очень люблю маму`
- `запомни боюсь пауков`

**Ограничения:**
- Максимум 4 слова после ключевой фразы
- Общий лимит памяти: 300 слов
- Ключевые слова: "запомни", "не забудь", "это важно", "обязательно запомни"

### 2. Автоматическое подмешивание
При каждом обращении пользователя система:
1. Загружает долгосрочную память пользователя
2. Автоматически добавляет факты в системный промпт LLM
3. LLM получает контекст вида:
   ```
   Ты дружелюбный голосовой ассистент. Вот что ты знаешь о пользователе:
   Пользователь просил запомнить: не люблю лето
   Пользователь просил запомнить: очень люблю маму
   Пользователь просил запомнить: боюсь пауков
   ```

### 3. Команды памяти
Пользователь может запросить свои факты:
- `что ты помнишь`
- `вспомни`
- `помнишь`

## Настройки в config.yaml

```yaml
MEMORY:
  LONG_TERM:
    MAX_WORDS: 300                    # Максимум слов в памяти
    MAX_WORDS_PER_ENTRY: 4           # Максимум слов в одной записи
    AUTO_INCLUDE: true               # Автоподмешивание
    MAX_ENTRIES_TO_INCLUDE: 10       # Максимум записей для подмешивания
    SAVE_PHRASES: ["запомни", "не забудь", "это важно", "обязательно запомни"]
    RECALL_PHRASES: ["вспомни", "помнишь", "что ты помнишь"]
```

## Интеграция с чатами

### Twitch/YouTube
- Память автоматически подмешивается при каждом обращении
- Факты сохраняются в файл `memory/users/{user_id}.json`
- LLM всегда знает предпочтения пользователя

### Telegram
- Аналогично Twitch/YouTube
- Индивидуальная память для каждого пользователя

### Локальный голосовой чат
- Память сохраняется под ID "local"
- Работает так же, как и для других источников

## Примеры использования

### Сохранение фактов
```
Пользователь: запомни не люблю лето
Ассистент: Запомнила! Не люблю лето.

Пользователь: запомни очень люблю маму
Ассистент: Запомнила! Очень люблю маму.
```

### Использование памяти
```
Пользователь: что мне заказать на ужин?
Ассистент: (знает, что пользователь любит пиццу) 
         Может, пиццу? Ты же говорил, что любишь её!

Пользователь: что ты помнишь обо мне?
Ассистент: Вот что я помню:
         - не люблю лето
         - очень люблю маму
         - боюсь пауков
```

## Технические детали

### Файлы памяти
- `memory/users/{user_id}.json` - долгосрочная память пользователя
- `memory/persistent/` - важные события по дням
- `long_term_memory.json` - глобальная память (устарело)

### Классы
- `MemoryManager` - основной менеджер памяти
- `ShortTermMemory` - краткосрочная память (контекст)
- `RoleManager` - управление ролями для разных источников

### Функции
- `get_user_context(user_id, source)` - получение контекста пользователя
- `save_user_memory(user_id)` - сохранение памяти
- `memory.get_context_as_system_prompt()` - получение системного промпта с памятью

## Тестирование

Запустите тесты для проверки системы:
```bash
python test_memory.py              # Базовый тест памяти
python test_memory_integration.py  # Тест интеграции с чатами
python test_final_memory.py        # Финальный тест
```

## Преимущества

1. **Персонализация**: LLM помнит предпочтения каждого пользователя
2. **Автоматичность**: Не требует ручного управления
3. **Эффективность**: Ограничения предотвращают переполнение памяти
4. **Гибкость**: Настраиваемые лимиты и ключевые слова
5. **Интеграция**: Работает со всеми источниками (Twitch, YouTube, Telegram, голос)

## Ограничения

- Максимум 4 слова в одной записи
- Общий лимит 300 слов на пользователя
- Только факты, не диалоги
- Ключевые слова обязательны для сохранения 